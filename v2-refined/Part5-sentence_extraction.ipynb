{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "adf4ccb9",
      "metadata": {
        "executionInfo": {
          "elapsed": 279,
          "status": "ok",
          "timestamp": 1697698109461,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "adf4ccb9"
      },
      "outputs": [],
      "source": [
        "#Start"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f81db954",
      "metadata": {
        "id": "f81db954"
      },
      "source": [
        "### Code Summary\n",
        "\n",
        "The JSON file containing filtered abstracts is loaded and converted into a dictionary for quicker access. The TSV file containing SNP data is loaded, and mentions are converted to lowercase. For every row, the mention text is substituted with the corresponding Concept ID (RSID) in the abstract. The unique RSIDs are collected and saved to a file. The abstracts are then split into sentences using NLTK's sentence tokenizer. Using multiprocessing, we extract sentences containing any of the RSIDs for each PMID. The PMID-to-sentence list mappings are then saved as a JSON file. The final output is a file where each line corresponds to a PMID, with the sentences containing RSID mentions from its abstract. The key steps involved in the process are: \n",
        "1. Substituting mentions with Concept IDs \n",
        "2. Splitting into sentences \n",
        "3. Extracting sentences with RSIDs \n",
        "4. Saving the PMID-to-sentences mapping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "aeea487d",
      "metadata": {
        "executionInfo": {
          "elapsed": 559,
          "status": "ok",
          "timestamp": 1697698111764,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "aeea487d"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import warnings\n",
        "import pickle\n",
        "import shutil\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "rLrW00jgrda6",
      "metadata": {
        "executionInfo": {
          "elapsed": 1472,
          "status": "ok",
          "timestamp": 1697698127508,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "rLrW00jgrda6"
      },
      "outputs": [],
      "source": [
        "zip_file_path = './filtered_snp_abstracts.zip'\n",
        "extract_to_path = './'\n",
        "\n",
        "# Extract the zip file\n",
        "shutil.unpack_archive(zip_file_path, extract_to_path, 'zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "53a6ffbc",
      "metadata": {
        "executionInfo": {
          "elapsed": 1507,
          "status": "ok",
          "timestamp": 1697698138227,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "53a6ffbc"
      },
      "outputs": [],
      "source": [
        "file_path = \"./filtered_snp_abstracts.json\"\n",
        "with open(file_path, \"r\") as f:\n",
        "    abstracts_data = [json.loads(line) for line in f]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1dfbda48",
      "metadata": {
        "executionInfo": {
          "elapsed": 569,
          "status": "ok",
          "timestamp": 1697698141202,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "1dfbda48"
      },
      "outputs": [],
      "source": [
        "# Convert to dict for efficient queries and make text case-insensitive\n",
        "abstracts_dict = {entry['ID']: entry['Abstract'].lower() for entry in abstracts_data}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "12741e75",
      "metadata": {
        "executionInfo": {
          "elapsed": 3077,
          "status": "ok",
          "timestamp": 1697698145355,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "12741e75"
      },
      "outputs": [],
      "source": [
        "# Load the TSV file\n",
        "file_path = \"./filtered_snp_data.tsv\"\n",
        "snp_df = pd.read_csv(file_path, delimiter='\\t')\n",
        "\n",
        "# Convert mentions to lowercase for matching\n",
        "snp_df['Mentions'] = snp_df['Mentions'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "305059f4",
      "metadata": {
        "executionInfo": {
          "elapsed": 104966,
          "status": "ok",
          "timestamp": 1697698251424,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "305059f4"
      },
      "outputs": [],
      "source": [
        "# List to store unique RSIDs replaced\n",
        "rsid_tokens = []\n",
        "\n",
        "# Replace mentions in abstracts with Concept ID\n",
        "for _, row in snp_df.iterrows():\n",
        "    pmid = row['PMID']\n",
        "    mention = row['Mentions']\n",
        "    concept_id = row['Concept ID']\n",
        "    if pmid in abstracts_dict:\n",
        "        # Replacing the mention with the Concept ID\n",
        "        abstracts_dict[pmid] = abstracts_dict[pmid].replace(mention, f'{concept_id}')\n",
        "        rsid_tokens.append(concept_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8uQbq5Ejv20v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 275,
          "status": "ok",
          "timestamp": 1697698255316,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "8uQbq5Ejv20v",
        "outputId": "4ce4fe4f-b7f0-4490-f4f1-ea556f815da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved rsid_tokens to ./rsid_tokens.pkl\n"
          ]
        }
      ],
      "source": [
        "rsid_tokens = list(set(rsid_tokens))\n",
        "\n",
        "#Store RSID tokens\n",
        "file_path = \"./rsid_tokens.pkl\"\n",
        "\n",
        "# Save the list to the specified file using pickle\n",
        "with open(file_path, 'wb') as f:\n",
        "    pickle.dump(rsid_tokens, f)\n",
        "print(f\"Saved rsid_tokens to {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "469006df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 273,
          "status": "ok",
          "timestamp": 1697698261233,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "469006df",
        "outputId": "4e992314-0e59-4462-dcd1-88c268d611fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total abstracts where the mentions are changed: 107631 out of 107631\n"
          ]
        }
      ],
      "source": [
        "changed_abstracts = sum(1 for abstract in abstracts_dict.values() if \"rs\" in abstract)\n",
        "print(f\"Total abstracts where the mentions are changed: {changed_abstracts} out of {len(abstracts_dict)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b158e5e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 281,
          "status": "ok",
          "timestamp": 1697698264283,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "b158e5e6",
        "outputId": "f6cc70ce-7d4b-4cec-fac6-143ea38f7d7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "interleukin 6 (il6) plays key roles in hematopoiesis, immune, and acute phase responses. dysregulated il6 expression is implicated in diseases such as atherosclerosis and arthritis. we have examined the functional effect of four polymorphisms in the il6 promoter (rs1800797, rs1800796, -373a(n)t(n), rs1800795) by identifying the naturally occurring haplotypes and comparing their effects on reporter gene expression. the results indicate different transcriptional regulation in the ecv304 cell line compared with the hela cell line, suggesting cell type-specific regulation of il6 expression. the haplotypes showed functional differences in the ecv304 cell line; transcription was higher from the gg9/11g haplotype and lower from the ag8/12g allele. the differences suggest that more than one of the polymorphic sites is functional; the base differences at distinct polymorphic sites do not act independently of one another, and one polymorphism influences the functional effect of variation at other polymorphic sites. these results show that genetic polymorphisms in the promoter influence il6 transcription not by a simple additive mechanism but rather through complex interactions determined by the haplotype.\n",
            "\n",
            "\n",
            "             PMID Concept ID   Mentions Resource\n",
            "1346719  10747905  rs1800797  -597g-->a    tmVar\n",
            "1346720  10747905  rs1800796  -572g-->c    tmVar\n",
            "1346721  10747905  rs1800795  -174g-->c    tmVar\n"
          ]
        }
      ],
      "source": [
        "#Print Random Abstract to check if Mentions are replaced with RSID\n",
        "print(abstracts_dict[10747905])\n",
        "print('\\n')\n",
        "print(snp_df[snp_df['PMID'] == 10747905])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "nH3jGl4oBcgf",
      "metadata": {
        "executionInfo": {
          "elapsed": 266,
          "status": "ok",
          "timestamp": 1697698266548,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "nH3jGl4oBcgf"
      },
      "outputs": [],
      "source": [
        "#Sentence Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "yWw3j99PkhlD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5479,
          "status": "ok",
          "timestamp": 1697698273862,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "yWw3j99PkhlD",
        "outputId": "0d565bf7-0567-498e-d937-4c2b3366d712"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import json\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "UfgOgn_1A3d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3154911,
          "status": "ok",
          "timestamp": 1697701436607,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "UfgOgn_1A3d3",
        "outputId": "4a269530-7964-4076-9775-d770eb0bc2d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting RSID sentences: 100%|██████████| 107631/107631 [52:18<00:00, 34.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File saved to /rsid_sentences.json\n"
          ]
        }
      ],
      "source": [
        "def extract_rsid_sentences_for_pmid(pmid_abstract_tuple):\n",
        "    \"\"\"Extract sentences containing RSID tokens from a given abstract for a PMID.\"\"\"\n",
        "    pmid, abstract = pmid_abstract_tuple\n",
        "    sentences = [sentence for sentence in sent_tokenize(abstract) if any(rsid in sentence for rsid in rsid_tokens_set)]\n",
        "    return (pmid, sentences)\n",
        "\n",
        "# Convert rsid_tokens list to set for faster membership checks\n",
        "rsid_tokens_set = set(rsid_tokens)\n",
        "\n",
        "# Dictionary to store PMID to list of sentences containing RSIDs\n",
        "pmid_to_rsid_sentences = {}\n",
        "\n",
        "# Use ProcessPoolExecutor to parallelize the extraction\n",
        "with ProcessPoolExecutor() as executor:\n",
        "    results = list(tqdm.tqdm(executor.map(extract_rsid_sentences_for_pmid, abstracts_dict.items()), total=len(abstracts_dict), desc=\"Extracting RSID sentences\"))\n",
        "\n",
        "# Populate the dictionary with the results\n",
        "for pmid, sentences in results:\n",
        "    if sentences:\n",
        "        pmid_to_rsid_sentences[pmid] = sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "-fj09qn85MNB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1302,
          "status": "ok",
          "timestamp": 1697701492310,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -660
        },
        "id": "-fj09qn85MNB",
        "outputId": "30c8df1c-4cc2-42be-a2f3-9728b788a6f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File saved to ./rsid_sentences.json\n"
          ]
        }
      ],
      "source": [
        "# Define the path where you want to save the file on your Google Drive\n",
        "file_path = \"./rsid_sentences.json\"\n",
        "\n",
        "# Save each PMID and its sentences as a separate line in the file\n",
        "with open(file_path, 'w') as file:\n",
        "    for pmid, sentences in pmid_to_rsid_sentences.items():\n",
        "        file.write(json.dumps({pmid: sentences}) + \"\\n\")\n",
        "\n",
        "print(f\"File saved to {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dZAo_FUyy_f",
      "metadata": {
        "id": "0dZAo_FUyy_f"
      },
      "outputs": [],
      "source": [
        "#END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hwNXhQlhyy0E",
      "metadata": {
        "id": "hwNXhQlhyy0E"
      },
      "outputs": [],
      "source": [
        "#Sentences Extracted."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
